{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.expanduser(\"~/Desktop/moodlyze/data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/issa/Desktop/moodlyze/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to /Users/issa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/issa/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/issa/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/issa/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/issa/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "from pipeline.downloading import retrieve_data_from_kaggle\n",
    "from pipeline.cleaning import load_and_clean_data\n",
    "from pipeline.saving import connect_to_mongodb, insert_data_to_mongodb, preview_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier raw_tweets.csv est déjà présent dans /Users/issa/Desktop/moodlyze/data/raw\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Download Dataset from Kaggle\n",
    "kaggle_dataset_name = \"crowdflower/twitter-airline-sentiment\"\n",
    "output_filename = \"raw_tweets.csv\"\n",
    "retrieve_data_from_kaggle(kaggle_dataset_name, output_filename, max_entries=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avant nettoyage : Index(['tweet_id', 'sentiment', 'sentiment_confidence', 'negativereason',\n",
      "       'negativereason_confidence', 'airline', 'airline_sentiment_gold',\n",
      "       'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
      "       'tweet_created', 'tweet_location', 'user_timezone'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning text: 100%|██████████| 5000/5000 [22:13<00:00,  3.75it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du dataset après équilibrage : 2439 entrées\n",
      "Taille du dataset après nettoyage : 5000 entrées\n",
      "Colonnes après nettoyage : Index(['tweet_id', 'sentiment', 'sentiment_confidence', 'text',\n",
      "       'tweet_created', 'cleaned_text'],\n",
      "      dtype='object')\n",
      "             tweet_id sentiment  sentiment_confidence  \\\n",
      "0  570103012380667904  negative                   1.0   \n",
      "1  568579388704292864  negative                   1.0   \n",
      "2  568509134276050945  negative                   1.0   \n",
      "3  567822377473728513  negative                   1.0   \n",
      "4  570077847672328192  negative                   1.0   \n",
      "\n",
      "                                                text  \\\n",
      "0  @SouthwestAir hey remember that time you lost ...   \n",
      "1  @united - blamed weather lol 78 no wind and no...   \n",
      "2  @united thats because you didnt read my entire...   \n",
      "3  @united how can you not know, after two hours ...   \n",
      "4  @united Ice, which I totally understand. But w...   \n",
      "\n",
      "               tweet_created  \\\n",
      "0  2015-02-23 22:08:44 -0800   \n",
      "1  2015-02-19 17:14:24 -0800   \n",
      "2  2015-02-19 12:35:14 -0800   \n",
      "3  2015-02-17 15:06:19 -0800   \n",
      "4  2015-02-23 20:28:45 -0800   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  southwester hey remember that time you lose my...  \n",
      "1  united blame weather lot no wind and not a clo...  \n",
      "2  united that because you do n't read my entire ...  \n",
      "3  united how can you not know after two hour of ...  \n",
      "4  united ice which i totally understand but when...  \n",
      "Index(['tweet_id', 'sentiment', 'sentiment_confidence', 'text',\n",
      "       'tweet_created', 'cleaned_text'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define paths and load data\n",
    "dataset_path = os.path.expanduser(\"~/Desktop/moodlyze/data/raw/raw_tweets.csv\")\n",
    "cleaned_dataset_path = os.path.expanduser(\"~/Desktop/moodlyze/data/processed/cleaned_tweets.csv\")\n",
    "\n",
    "# Load and clean the data\n",
    "df = load_and_clean_data(dataset_path, cleaned_dataset_path)\n",
    "print(df.head(5))\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweet_id', 'sentiment', 'sentiment_confidence', 'text',\n",
      "       'tweet_created', 'cleaned_text'],\n",
      "      dtype='object')\n",
      "Insertion en cours... 2439\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 39 documents dans MongoDB sous la collection : tweets\n",
      "Insertion terminée.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Connect to MongoDB and insert data\n",
    "db = connect_to_mongodb()\n",
    "data = df.to_dict(orient='records')\n",
    "print(df.columns)\n",
    "insert_data_to_mongodb(db, 'tweets',data, max_records = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Preview inserted data\n",
    "# preview_data(db, 'tweets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
