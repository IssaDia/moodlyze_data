{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.expanduser(\"~/Desktop/moodlyze/data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/issa/Desktop/moodlyze/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to /Users/issa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/issa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/issa/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pipeline.downloading import retrieve_data_from_kaggle\n",
    "from pipeline.cleaning import load_and_clean_data\n",
    "from pipeline.saving import connect_to_mongodb, insert_data_to_mongodb, preview_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier raw_tweets.csv est déjà présent dans /Users/issa/Desktop/moodlyze/data/raw\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Download Dataset from Kaggle\n",
    "kaggle_dataset_name = \"kazanova/sentiment140\"\n",
    "output_filename = \"raw_tweets.csv\"\n",
    "retrieve_data_from_kaggle(kaggle_dataset_name, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avant nettoyage : Index(['id', 'date', 'user', 'text'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning text: 100%|██████████| 1599999/1599999 [00:12<00:00, 127173.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du dataset après nettoyage : 1599999 entrées\n",
      "Colonnes après nettoyage 2 :            id                          date           user  \\\n",
      "0  1467810672  Mon Apr 06 22:19:49 PDT 2009  scotthamilton   \n",
      "1  1467810917  Mon Apr 06 22:19:53 PDT 2009       mattycus   \n",
      "2  1467811184  Mon Apr 06 22:19:57 PDT 2009        ElleCTF   \n",
      "3  1467811193  Mon Apr 06 22:19:57 PDT 2009         Karoli   \n",
      "4  1467811372  Mon Apr 06 22:20:00 PDT 2009       joy_wolf   \n",
      "\n",
      "                                                text  \\\n",
      "0  is upset that he can't update his Facebook by ...   \n",
      "1  @Kenichan I dived many times for the ball. Man...   \n",
      "2    my whole body feels itchy and like its on fire    \n",
      "3  @nationwideclass no, it's not behaving at all....   \n",
      "4                      @Kwesidei not the whole crew    \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  is upset that he cant update his facebook by t...  \n",
      "1  kenichan i dived many times for the ball manag...  \n",
      "2     my whole body feels itchy and like its on fire  \n",
      "3  nationwideclass no its not behaving at all im ...  \n",
      "4                        kwesidei not the whole crew  \n",
      "Index(['id', 'date', 'user', 'text', 'cleaned_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define paths and load data\n",
    "dataset_path = os.path.expanduser(\"~/Desktop/moodlyze/data/raw/raw_tweets.csv\")\n",
    "cleaned_dataset_path = os.path.expanduser(\"~/Desktop/moodlyze/data/processed/cleaned_tweets.csv\")\n",
    "\n",
    "# Load and clean the data\n",
    "df = load_and_clean_data(dataset_path, cleaned_dataset_path)\n",
    "df.head(5)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'date', 'user', 'text', 'cleaned_text'], dtype='object')\n",
      "Colonnes qui seront insérées dans MongoDB:\n",
      "- id\n",
      "- date\n",
      "- user\n",
      "- text\n",
      "- cleaned_text\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Inséré 100 documents dans MongoDB sous la collection : tweets\n",
      "Insertion terminée.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Connect to MongoDB and insert data\n",
    "db = connect_to_mongodb()\n",
    "data = df.to_dict(orient='records')\n",
    "print(df.columns)\n",
    "insert_data_to_mongodb(db, 'tweets',data, max_records = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Preview inserted data\n",
    "# preview_data(db, 'tweets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
